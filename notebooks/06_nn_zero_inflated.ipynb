{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d613c70d",
   "metadata": {},
   "source": [
    "# 05 – Experimentos con NN tabular (embeddings + zero-inflated)\n",
    "\n",
    "En este notebook:\n",
    "- Evaluamos una arquitectura de red neuronal para predecir `Und_2a_percentage`.\n",
    "- Validamos el uso de embeddings vs numéricas.\n",
    "- Comparamos desempeño y analizamos importancia de variables.\n",
    "- Dejamos documentado el modelo elegido para producción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0bcc10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\n",
      "TARGET_COL  : Und_2a_percentage\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "cwd = Path().resolve()\n",
    "PROJECT_ROOT = None\n",
    "\n",
    "for parent in [cwd, *cwd.parents]:\n",
    "    if (parent / \"src\").is_dir():\n",
    "        PROJECT_ROOT = parent\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise RuntimeError(\"No se encontró carpeta 'src'.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.config.settings import TARGET_COL, RANDOM_STATE, MODELS_DIR, REPORTS_DIR\n",
    "from src.config.nn_config import NN_MODEL_SUBDIR, NN_KERAS_NAME, NN_PIPELINE_PKL\n",
    "from src.data.load_data import load_clean_dataset\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"TARGET_COL  :\", TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5d1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminando ruido/leakage: ['Rechazo_comp', 'rechazo_flag', 'Tecnologia', 'Tur', 'categoria_producto', 'semana_anio', 'g_art_id']\n",
      "Variables finales: 16\n",
      "Shape X_clean: (364832, 19)\n",
      "Embeddings: ['mp_categoria', 'mp_id', 'Tipo_TEJ', 'planta_id', 'seccion_id', 'producto_id', 'MP', 'maq_id', 'estilo_id', 'C']\n",
      "Numéricas : ['Col', 'Tal', 'Pas', 'Tal_Fert', 'Col_Fert', 'Componentes']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.features.nn_features import reorganize_features_final\n",
    "\n",
    "df = load_clean_dataset()\n",
    "y = df[TARGET_COL].values\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "X_clean, embed_cols, num_cols = reorganize_features_final(X)\n",
    "\n",
    "print(\"Shape X_clean:\", X_clean.shape)\n",
    "print(\"Embeddings:\", embed_cols)\n",
    "print(\"Numéricas :\", num_cols)\n",
    "\n",
    "\n",
    "# Observación:\n",
    "# En este punto congelamos qué columnas entran al modelo. \n",
    "# Cambios posteriores deben justificarse con nueva evidencia (perm importance, negocio, drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40741b",
   "metadata": {},
   "source": [
    "### Split y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde15e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs keys: dict_keys(['in_mp_categoria', 'in_mp_id', 'in_Tipo_TEJ', 'in_planta_id', 'in_seccion_id', 'in_producto_id', 'in_MP', 'in_maq_id', 'in_estilo_id', 'in_C', 'in_numerics'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.nn_preprocessing import preprocess_data\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_clean,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "train_inputs, test_inputs, encoders, n_nums, scaler = preprocess_data(\n",
    "    X_train_raw,\n",
    "    X_test_raw,\n",
    "    embed_cols,\n",
    "    num_cols,\n",
    ")\n",
    "\n",
    "print(\"Train inputs keys:\", train_inputs.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6b8e4",
   "metadata": {},
   "source": [
    "## Construcción y entrenamiento de la NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6d35568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0700 - rmse: 0.1682 - val_loss: 0.0113 - val_mae: 0.0664 - val_rmse: 0.1575 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0666 - rmse: 0.1579 - val_loss: 0.0110 - val_mae: 0.0670 - val_rmse: 0.1548 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0656 - rmse: 0.1555 - val_loss: 0.0109 - val_mae: 0.0663 - val_rmse: 0.1538 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0651 - rmse: 0.1542 - val_loss: 0.0108 - val_mae: 0.0663 - val_rmse: 0.1535 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0646 - rmse: 0.1530 - val_loss: 0.0108 - val_mae: 0.0627 - val_rmse: 0.1535 - learning_rate: 3.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0639 - rmse: 0.1519 - val_loss: 0.0108 - val_mae: 0.0637 - val_rmse: 0.1533 - learning_rate: 3.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0634 - rmse: 0.1511 - val_loss: 0.0108 - val_mae: 0.0618 - val_rmse: 0.1534 - learning_rate: 3.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0624 - rmse: 0.1492 - val_loss: 0.0107 - val_mae: 0.0638 - val_rmse: 0.1530 - learning_rate: 3.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0624 - rmse: 0.1490 - val_loss: 0.0107 - val_mae: 0.0651 - val_rmse: 0.1529 - learning_rate: 3.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0624 - rmse: 0.1486 - val_loss: 0.0107 - val_mae: 0.0644 - val_rmse: 0.1530 - learning_rate: 3.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0624 - rmse: 0.1484 - val_loss: 0.0107 - val_mae: 0.0645 - val_rmse: 0.1530 - learning_rate: 3.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0621 - rmse: 0.1481 - val_loss: 0.0108 - val_mae: 0.0654 - val_rmse: 0.1531 - learning_rate: 3.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0626 - rmse: 0.1479 - val_loss: 0.0108 - val_mae: 0.0646 - val_rmse: 0.1531 - learning_rate: 3.0000e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0621 - rmse: 0.1476 - val_loss: 0.0108 - val_mae: 0.0646 - val_rmse: 0.1531 - learning_rate: 3.0000e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0620 - rmse: 0.1478 - val_loss: 0.0108 - val_mae: 0.0644 - val_rmse: 0.1531 - learning_rate: 3.0000e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0620 - rmse: 0.1478 - val_loss: 0.0108 - val_mae: 0.0643 - val_rmse: 0.1531 - learning_rate: 3.0000e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0621 - rmse: 0.1478 - val_loss: 0.0108 - val_mae: 0.0645 - val_rmse: 0.1531 - learning_rate: 3.0000e-07\n",
      "Epoch 18/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0620 - rmse: 0.1477 - val_loss: 0.0108 - val_mae: 0.0645 - val_rmse: 0.1532 - learning_rate: 3.0000e-07\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "from src.models.nn_zero_inflated import build_dynamic_model_tuned\n",
    "\n",
    "model = build_dynamic_model_tuned(\n",
    "    embed_cols=embed_cols,\n",
    "    encoders=encoders,\n",
    "    n_numeric_features=n_nums,\n",
    "    learning_rate=3e-4,\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    callbacks.EarlyStopping(patience=8, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(patience=4),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    y_train,\n",
    "    validation_data=(test_inputs, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=cb,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Observacion:\n",
    "# “EarlyStopping\" y \"ReduceLROnPlateau\" reducen el riesgo de sobreentrenar y estabilizan el entrenamiento sin necesidad de grid-search manual de épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfbfd4",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b12579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
      "R2   : 0.7851\n",
      "MSE  : 0.023394\n",
      "RMSE : 0.152951\n",
      "MAE  : 0.064370\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "preds = model.predict(test_inputs).reshape(-1)\n",
    "\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"R2   : {r2:.4f}\")\n",
    "print(f\"MSE  : {mse:.6f}\")\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a758d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ History guardado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\history_nn.csv\n",
      "✅ Métricas guardadas en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\metrics_nn.json\n",
      "✅ Hyperparámetros guardados en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\hyperparams_nn.json\n",
      "✅ Model comparison actualizado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Guardar artefactos para dashboard / Streamlit\n",
    "\n",
    "# %%\n",
    "import json\n",
    "\n",
    "# Asegurar carpeta de reports\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Historia de entrenamiento (para los gráficos)\n",
    "history_df = pd.DataFrame(history.history)\n",
    "hist_path = REPORTS_DIR / \"history_nn.csv\"   # <--- el nombre que espera la app\n",
    "history_df.to_csv(hist_path, index_label=\"epoch\")\n",
    "print(\"✅ History guardado en:\", hist_path)\n",
    "\n",
    "# 2) Métricas agregadas (para las tarjetas de la app)\n",
    "metrics = {\n",
    "    \"model_name\": \"nn_zero_inflated_experiments\",\n",
    "    \"R2\": float(r2),\n",
    "    \"MSE\": float(mse),\n",
    "    \"RMSE\": float(rmse),\n",
    "    \"MAE\": float(mae),\n",
    "}\n",
    "metrics_path = REPORTS_DIR / \"metrics_nn.json\"\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "print(\"✅ Métricas guardadas en:\", metrics_path)\n",
    "\n",
    "# 3) Hyperparámetros básicos del experimento\n",
    "hyperparams = {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 32,\n",
    "    \"patience_es\": 8,\n",
    "    \"patience_lr\": 4,\n",
    "    \"test_size\": 0.2,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "hyper_path = REPORTS_DIR / \"hyperparams_nn.json\"\n",
    "hyper_path.write_text(json.dumps(hyperparams, indent=2), encoding=\"utf-8\")\n",
    "print(\"✅ Hyperparámetros guardados en:\", hyper_path)\n",
    "\n",
    "# 4) Tabla de comparación de modelos\n",
    "comp_path = REPORTS_DIR / \"model_comparison.csv\"\n",
    "row = {\"model\": \"nn_zero_inflated_experiments\", \"R2\": r2, \"RMSE\": rmse}\n",
    "\n",
    "if comp_path.exists():\n",
    "    comp_df = pd.read_csv(comp_path)\n",
    "    comp_df = pd.concat([comp_df, pd.DataFrame([row])], ignore_index=True)\n",
    "else:\n",
    "    comp_df = pd.DataFrame([row])\n",
    "\n",
    "comp_df.to_csv(comp_path, index=False)\n",
    "print(\"✅ Model comparison actualizado en:\", comp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab2d324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\data\\models\\nn_zero_inflated\\modelo_defectos.keras\n",
      "Pipeline guardado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\data\\models\\nn_zero_inflated\\pipeline_completo.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_dir = MODELS_DIR / NN_MODEL_SUBDIR\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "keras_path = model_dir / NN_KERAS_NAME\n",
    "pipe_path = model_dir / NN_PIPELINE_PKL\n",
    "\n",
    "model.save(keras_path)\n",
    "\n",
    "pipeline_artefactos = {\n",
    "    \"keras_model_path\": keras_path,\n",
    "    \"encoders\": encoders,\n",
    "    \"scaler\": scaler,\n",
    "    \"embed_cols\": embed_cols,\n",
    "    \"num_cols\": num_cols,\n",
    "}\n",
    "\n",
    "joblib.dump(pipeline_artefactos, pipe_path)\n",
    "\n",
    "print(\"Modelo guardado en:\", keras_path)\n",
    "print(\"Pipeline guardado en:\", pipe_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c85e22",
   "metadata": {},
   "source": [
    "### Importancia por permutación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65fc741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_seccion_id: ΔRMSE = 0.266891\n",
      "in_numerics: ΔRMSE = 0.056336\n",
      "in_producto_id: ΔRMSE = 0.013092\n",
      "in_mp_id: ΔRMSE = 0.010722\n",
      "in_maq_id: ΔRMSE = 0.000948\n",
      "in_estilo_id: ΔRMSE = 0.000229\n",
      "in_Tipo_TEJ: ΔRMSE = 0.000079\n",
      "in_mp_categoria: ΔRMSE = 0.000061\n",
      "in_MP: ΔRMSE = 0.000012\n",
      "in_planta_id: ΔRMSE = -0.000003\n"
     ]
    }
   ],
   "source": [
    "from src.models.importance import calculate_permutation_importance\n",
    "\n",
    "# Métricas de Keras: [loss, mae, rmse] -> rmse está en índice 2\n",
    "RMSE_INDEX = 2\n",
    "\n",
    "imps = calculate_permutation_importance(\n",
    "    model=model,\n",
    "    X_dict=test_inputs,\n",
    "    y_true=y_test,\n",
    "    metric_index=RMSE_INDEX,\n",
    "    sample_size=10000,\n",
    ")\n",
    "\n",
    "sorted_imps = sorted(imps.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for name, imp in sorted_imps[:10]:\n",
    "    print(f\"{name}: ΔRMSE = {imp:.6f}\")\n",
    "    \n",
    "\n",
    "# Observacion:\n",
    "# Permutation importance a nivel de input dict permite validar si la arquitectura está usando las señales correctas y justificar exclusiones futuras. \n",
    "# No es una explicación local estilo SHAP, pero es suficientemente estable para decisiones de feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0f2c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
