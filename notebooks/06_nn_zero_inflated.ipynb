{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d613c70d",
   "metadata": {},
   "source": [
    "# 06 – Experimentos con NN tabular (embeddings + zero-inflated)\n",
    "\n",
    "En este notebook:\n",
    "- Evaluamos una arquitectura de red neuronal para predecir `Und_2a_percentage`.\n",
    "- Validamos el uso de embeddings vs numéricas.\n",
    "- Comparamos desempeño y analizamos importancia de variables.\n",
    "- Dejamos documentado el modelo elegido para producción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bcc10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\n",
      "TARGET_COL  : Und_2a_percentage\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "cwd = Path().resolve()\n",
    "PROJECT_ROOT = None\n",
    "\n",
    "for parent in [cwd, *cwd.parents]:\n",
    "    if (parent / \"src\").is_dir():\n",
    "        PROJECT_ROOT = parent\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise RuntimeError(\"No se encontró carpeta 'src'.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.config.settings import TARGET_COL, RANDOM_STATE, MODELS_DIR, REPORTS_DIR\n",
    "from src.config.nn_config import NN_MODEL_SUBDIR, NN_KERAS_NAME, NN_PIPELINE_PKL\n",
    "from src.data.load_data import load_clean_dataset\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"TARGET_COL  :\", TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5d1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminando ruido/leakage: ['Rechazo_comp', 'rechazo_flag', 'Tecnologia', 'Tur', 'categoria_producto', 'semana_anio', 'g_art_id']\n",
      "Variables finales: 16\n",
      "Shape X_clean: (364832, 19)\n",
      "Embeddings: ['MP', 'planta_id', 'seccion_id', 'mp_id', 'Tipo_TEJ', 'producto_id', 'estilo_id', 'mp_categoria', 'C', 'maq_id']\n",
      "Numéricas : ['Col_Fert', 'Componentes', 'Pas', 'Tal', 'Col', 'Tal_Fert']\n",
      "Percentiles target filtrado: [0.         0.00980392 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.features.nn_features import reorganize_features_final\n",
    "\n",
    "df = load_clean_dataset()\n",
    "\n",
    "# --- Target original ---\n",
    "y_raw = df[TARGET_COL].values\n",
    "\n",
    "# --- FILTRADO SUAVE DE OUTLIERS EN EL TARGET ---\n",
    "q_low, q_high = np.percentile(y_raw, [1, 99])  # puedes ajustar 0.5 y 99.5 si hace falta\n",
    "mask = (y_raw >= q_low) & (y_raw <= q_high)\n",
    "\n",
    "df_filt = df.loc[mask].copy()\n",
    "\n",
    "y = df_filt[TARGET_COL].values        # target filtrado\n",
    "X = df_filt.drop(columns=[TARGET_COL])\n",
    "\n",
    "X_clean, embed_cols, num_cols = reorganize_features_final(X)\n",
    "\n",
    "print(\"Shape X_clean:\", X_clean.shape)\n",
    "print(\"Embeddings:\", embed_cols)\n",
    "print(\"Numéricas :\", num_cols)\n",
    "print(\"Percentiles target filtrado:\", np.percentile(y, [0, 50, 90, 95, 99]))\n",
    "\n",
    "\n",
    "\n",
    "# Observación:\n",
    "# En este punto congelamos qué columnas entran al modelo. \n",
    "# Cambios posteriores deben justificarse con nueva evidencia (perm importance, negocio, drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40741b",
   "metadata": {},
   "source": [
    "### Split y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde15e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs keys: dict_keys(['in_MP', 'in_planta_id', 'in_seccion_id', 'in_mp_id', 'in_Tipo_TEJ', 'in_producto_id', 'in_estilo_id', 'in_mp_categoria', 'in_C', 'in_maq_id', 'in_numerics'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.nn_preprocessing import preprocess_data\n",
    "\n",
    "# --- Target transformado a log1p ---\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_clean,\n",
    "    y_log,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "\n",
    "train_inputs, test_inputs, encoders, n_nums, scaler = preprocess_data(\n",
    "    X_train_raw,\n",
    "    X_test_raw,\n",
    "    embed_cols,\n",
    "    num_cols,\n",
    ")\n",
    "\n",
    "print(\"Train inputs keys:\", train_inputs.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6b8e4",
   "metadata": {},
   "source": [
    "## Construcción y entrenamiento de la NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d35568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - loss: 0.0076 - mae: 0.0644 - rmse: 0.1257 - val_loss: 0.0076 - val_mae: 0.0688 - val_rmse: 0.1259 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.0064 - mae: 0.0582 - rmse: 0.1158 - val_loss: 0.0075 - val_mae: 0.0718 - val_rmse: 0.1246 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0559 - rmse: 0.1132 - val_loss: 0.0065 - val_mae: 0.0648 - val_rmse: 0.1163 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.0060 - mae: 0.0540 - rmse: 0.1117 - val_loss: 0.0060 - val_mae: 0.0562 - val_rmse: 0.1113 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.0059 - mae: 0.0524 - rmse: 0.1105 - val_loss: 0.0059 - val_mae: 0.0556 - val_rmse: 0.1105 - learning_rate: 3.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.0058 - mae: 0.0518 - rmse: 0.1100 - val_loss: 0.0058 - val_mae: 0.0527 - val_rmse: 0.1103 - learning_rate: 3.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.0058 - mae: 0.0516 - rmse: 0.1094 - val_loss: 0.0059 - val_mae: 0.0519 - val_rmse: 0.1106 - learning_rate: 3.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - loss: 0.0057 - mae: 0.0511 - rmse: 0.1088 - val_loss: 0.0059 - val_mae: 0.0520 - val_rmse: 0.1104 - learning_rate: 3.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.0057 - mae: 0.0509 - rmse: 0.1086 - val_loss: 0.0058 - val_mae: 0.0504 - val_rmse: 0.1102 - learning_rate: 3.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0508 - rmse: 0.1083 - val_loss: 0.0058 - val_mae: 0.0507 - val_rmse: 0.1102 - learning_rate: 3.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0506 - rmse: 0.1079 - val_loss: 0.0058 - val_mae: 0.0506 - val_rmse: 0.1102 - learning_rate: 3.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0504 - rmse: 0.1076 - val_loss: 0.0059 - val_mae: 0.0537 - val_rmse: 0.1111 - learning_rate: 3.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0496 - rmse: 0.1064 - val_loss: 0.0059 - val_mae: 0.0514 - val_rmse: 0.1108 - learning_rate: 3.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0494 - rmse: 0.1062 - val_loss: 0.0059 - val_mae: 0.0512 - val_rmse: 0.1107 - learning_rate: 3.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0492 - rmse: 0.1060 - val_loss: 0.0059 - val_mae: 0.0513 - val_rmse: 0.1107 - learning_rate: 3.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0492 - rmse: 0.1058 - val_loss: 0.0059 - val_mae: 0.0512 - val_rmse: 0.1105 - learning_rate: 3.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0491 - rmse: 0.1057 - val_loss: 0.0059 - val_mae: 0.0512 - val_rmse: 0.1107 - learning_rate: 3.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0054 - mae: 0.0491 - rmse: 0.1057 - val_loss: 0.0059 - val_mae: 0.0519 - val_rmse: 0.1108 - learning_rate: 3.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.0053 - mae: 0.0490 - rmse: 0.1054 - val_loss: 0.0059 - val_mae: 0.0513 - val_rmse: 0.1107 - learning_rate: 3.0000e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0053 - mae: 0.0490 - rmse: 0.1054 - val_loss: 0.0059 - val_mae: 0.0510 - val_rmse: 0.1107 - learning_rate: 3.0000e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - loss: 0.0053 - mae: 0.0489 - rmse: 0.1053 - val_loss: 0.0059 - val_mae: 0.0513 - val_rmse: 0.1108 - learning_rate: 3.0000e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0053 - mae: 0.0489 - rmse: 0.1054 - val_loss: 0.0059 - val_mae: 0.0513 - val_rmse: 0.1108 - learning_rate: 3.0000e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0053 - mae: 0.0489 - rmse: 0.1053 - val_loss: 0.0059 - val_mae: 0.0513 - val_rmse: 0.1108 - learning_rate: 3.0000e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "from src.models.nn_zero_inflated import build_dynamic_model_tuned\n",
    "\n",
    "model = build_dynamic_model_tuned(\n",
    "    embed_cols=embed_cols,\n",
    "    encoders=encoders,\n",
    "    n_numeric_features=n_nums,\n",
    "    learning_rate=3e-4,\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    callbacks.EarlyStopping(monitor=\"val_rmse\", patience=12, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(patience=6),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    y_train,\n",
    "    validation_data=(test_inputs, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=cb,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Observacion:\n",
    "# “EarlyStopping\" y \"ReduceLROnPlateau\" reducen el riesgo de sobreentrenar y estabilizan el entrenamiento sin necesidad de grid-search manual de épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfbfd4",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b12579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "R2   : 0.7846\n",
      "MSE  : 0.023453\n",
      "RMSE : 0.153144\n",
      "MAE  : 0.061166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Predicciones en espacio log\n",
    "preds_log = model.predict(test_inputs).reshape(-1)\n",
    "\n",
    "# Volver al espacio original del negocio\n",
    "y_test_lin = np.expm1(y_test)       # deshacemos log1p\n",
    "preds_lin  = np.expm1(preds_log)\n",
    "\n",
    "mse = mean_squared_error(y_test_lin, preds_lin)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_lin, preds_lin)\n",
    "r2 = r2_score(y_test_lin, preds_lin)\n",
    "\n",
    "print(f\"R2   : {r2:.4f}\")\n",
    "print(f\"MSE  : {mse:.6f}\")\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a758d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ History guardado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\history_nn.csv\n",
      "✅ Métricas guardadas en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\metrics_nn.json\n",
      "✅ Hyperparámetros guardados en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\hyperparams_nn.json\n",
      "✅ Model comparison actualizado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\reports\\model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Guardar artefactos para dashboard / Streamlit\n",
    "\n",
    "# %%\n",
    "import json\n",
    "\n",
    "# Asegurar carpeta de reports\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Historia de entrenamiento (para los gráficos)\n",
    "history_df = pd.DataFrame(history.history)\n",
    "hist_path = REPORTS_DIR / \"history_nn.csv\"   # <--- el nombre que espera la app\n",
    "history_df.to_csv(hist_path, index_label=\"epoch\")\n",
    "print(\"✅ History guardado en:\", hist_path)\n",
    "\n",
    "# 2) Métricas agregadas (para las tarjetas de la app)\n",
    "metrics = {\n",
    "    \"model_name\": \"nn_zero_inflated\",\n",
    "    \"R2\": float(r2),\n",
    "    \"MSE\": float(mse),\n",
    "    \"RMSE\": float(rmse),\n",
    "    \"MAE\": float(mae),\n",
    "}\n",
    "metrics_path = REPORTS_DIR / \"metrics_nn.json\"\n",
    "metrics_path.write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "print(\"✅ Métricas guardadas en:\", metrics_path)\n",
    "\n",
    "# 3) Hyperparámetros básicos del experimento\n",
    "hyperparams = {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 32,\n",
    "    \"patience_es\": 8,\n",
    "    \"patience_lr\": 4,\n",
    "    \"test_size\": 0.2,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "}\n",
    "hyper_path = REPORTS_DIR / \"hyperparams_nn.json\"\n",
    "hyper_path.write_text(json.dumps(hyperparams, indent=2), encoding=\"utf-8\")\n",
    "print(\"✅ Hyperparámetros guardados en:\", hyper_path)\n",
    "\n",
    "# 4) Tabla de comparación de modelos\n",
    "comp_path = REPORTS_DIR / \"model_comparison.csv\"\n",
    "row = {\"model\": \"nn_zero_inflated_experiments\", \"R2\": r2, \"RMSE\": rmse}\n",
    "\n",
    "if comp_path.exists():\n",
    "    comp_df = pd.read_csv(comp_path)\n",
    "    comp_df = pd.concat([comp_df, pd.DataFrame([row])], ignore_index=True)\n",
    "else:\n",
    "    comp_df = pd.DataFrame([row])\n",
    "\n",
    "comp_df.to_csv(comp_path, index=False)\n",
    "print(\"✅ Model comparison actualizado en:\", comp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2d324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\data\\models\\nn_zero_inflated\\modelo_defectos.keras\n",
      "Pipeline guardado en: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\\src\\data\\models\\nn_zero_inflated\\pipeline_completo.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_dir = MODELS_DIR / NN_MODEL_SUBDIR\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "keras_path = model_dir / NN_KERAS_NAME\n",
    "pipe_path = model_dir / NN_PIPELINE_PKL\n",
    "\n",
    "model.save(keras_path)\n",
    "\n",
    "pipeline_artefactos = {\n",
    "    \"keras_model_path\": keras_path,\n",
    "    \"encoders\": encoders,\n",
    "    \"scaler\": scaler,\n",
    "    \"embed_cols\": embed_cols,\n",
    "    \"num_cols\": num_cols,\n",
    "}\n",
    "\n",
    "joblib.dump(pipeline_artefactos, pipe_path)\n",
    "\n",
    "print(\"Modelo guardado en:\", keras_path)\n",
    "print(\"Pipeline guardado en:\", pipe_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c85e22",
   "metadata": {},
   "source": [
    "### Importancia por permutación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65fc741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_seccion_id: ΔRMSE = 0.176722\n",
      "in_numerics: ΔRMSE = 0.040530\n",
      "in_producto_id: ΔRMSE = 0.011301\n",
      "in_mp_id: ΔRMSE = 0.011259\n",
      "in_maq_id: ΔRMSE = 0.002162\n",
      "in_C: ΔRMSE = 0.000132\n",
      "in_Tipo_TEJ: ΔRMSE = 0.000107\n",
      "in_estilo_id: ΔRMSE = 0.000021\n",
      "in_MP: ΔRMSE = 0.000005\n",
      "in_planta_id: ΔRMSE = -0.000000\n"
     ]
    }
   ],
   "source": [
    "from src.models.importance import calculate_permutation_importance\n",
    "\n",
    "# Métricas de Keras: [loss, mae, rmse] -> rmse está en índice 2\n",
    "RMSE_INDEX = 2\n",
    "\n",
    "imps = calculate_permutation_importance(\n",
    "    model=model,\n",
    "    X_dict=test_inputs,\n",
    "    y_true=y_test,\n",
    "    metric_index=RMSE_INDEX,\n",
    "    sample_size=10000,\n",
    ")\n",
    "\n",
    "sorted_imps = sorted(imps.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for name, imp in sorted_imps[:10]:\n",
    "    print(f\"{name}: ΔRMSE = {imp:.6f}\")\n",
    "    \n",
    "\n",
    "# Observacion:\n",
    "# Permutation importance a nivel de input dict permite validar si la arquitectura está usando las señales correctas y justificar exclusiones futuras. \n",
    "# No es una explicación local estilo SHAP, pero es suficientemente estable para decisiones de feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0f2c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
