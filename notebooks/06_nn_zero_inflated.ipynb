{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d613c70d",
   "metadata": {},
   "source": [
    "# 05 – Experimentos con NN tabular (embeddings + zero-inflated)\n",
    "\n",
    "En este notebook:\n",
    "- Evaluamos una arquitectura de red neuronal para predecir `Und_2a_percentage`.\n",
    "- Validamos el uso de embeddings vs numéricas.\n",
    "- Comparamos desempeño y analizamos importancia de variables.\n",
    "- Dejamos documentado el modelo elegido para producción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bcc10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: D:\\Users\\dhcertug\\OneDrive - Crystal S.A.S\\Documentos\\HOME\\00_PERSONAL\\02_CURSOS\\PROYECTO\\Proyecto_analisis_intermedio_udea\n",
      "TARGET_COL  : Und_2a_percentage\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "cwd = Path().resolve()\n",
    "PROJECT_ROOT = None\n",
    "\n",
    "for parent in [cwd, *cwd.parents]:\n",
    "    if (parent / \"src\").is_dir():\n",
    "        PROJECT_ROOT = parent\n",
    "        break\n",
    "\n",
    "if PROJECT_ROOT is None:\n",
    "    raise RuntimeError(\"No se encontró carpeta 'src'.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.config.settings import TARGET_COL, RANDOM_STATE, MODELS_DIR\n",
    "from src.config.nn_config import NN_MODEL_SUBDIR, NN_KERAS_NAME, NN_PIPELINE_PKL\n",
    "from src.data.load_data import load_clean_dataset\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"TARGET_COL  :\", TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5d1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminando ruido/leakage: ['Rechazo_comp', 'rechazo_flag', 'Tecnologia', 'Tur', 'categoria_producto', 'semana_anio', 'g_art_id']\n",
      "Variables finales: 16\n",
      "Shape X_clean: (364832, 19)\n",
      "Embeddings: ['mp_categoria', 'mp_id', 'Tipo_TEJ', 'planta_id', 'seccion_id', 'producto_id', 'MP', 'maq_id', 'estilo_id', 'C']\n",
      "Numéricas : ['Col', 'Tal', 'Pas', 'Tal_Fert', 'Col_Fert', 'Componentes']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.features.nn_features import reorganize_features_final\n",
    "\n",
    "df = load_clean_dataset()\n",
    "y = df[TARGET_COL].values\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "X_clean, embed_cols, num_cols = reorganize_features_final(X)\n",
    "\n",
    "print(\"Shape X_clean:\", X_clean.shape)\n",
    "print(\"Embeddings:\", embed_cols)\n",
    "print(\"Numéricas :\", num_cols)\n",
    "\n",
    "\n",
    "# Observación:\n",
    "# En este punto congelamos qué columnas entran al modelo. \n",
    "# Cambios posteriores deben justificarse con nueva evidencia (perm importance, negocio, drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40741b",
   "metadata": {},
   "source": [
    "### Split y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde15e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs keys: dict_keys(['in_mp_categoria', 'in_mp_id', 'in_Tipo_TEJ', 'in_planta_id', 'in_seccion_id', 'in_producto_id', 'in_MP', 'in_maq_id', 'in_estilo_id', 'in_C', 'in_numerics'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.nn_preprocessing import preprocess_data\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_clean,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "train_inputs, test_inputs, encoders, n_nums, scaler = preprocess_data(\n",
    "    X_train_raw,\n",
    "    X_test_raw,\n",
    "    embed_cols,\n",
    "    num_cols,\n",
    ")\n",
    "\n",
    "print(\"Train inputs keys:\", train_inputs.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6b8e4",
   "metadata": {},
   "source": [
    "## Construcción y entrenamiento de la NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d35568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0697 - rmse: 0.1677 - val_loss: 0.0114 - val_mae: 0.0665 - val_rmse: 0.1577 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0665 - rmse: 0.1578 - val_loss: 0.0110 - val_mae: 0.0659 - val_rmse: 0.1551 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0657 - rmse: 0.1555 - val_loss: 0.0110 - val_mae: 0.0657 - val_rmse: 0.1550 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0651 - rmse: 0.1539 - val_loss: 0.0108 - val_mae: 0.0655 - val_rmse: 0.1534 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0644 - rmse: 0.1528 - val_loss: 0.0108 - val_mae: 0.0647 - val_rmse: 0.1533 - learning_rate: 3.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0640 - rmse: 0.1519 - val_loss: 0.0108 - val_mae: 0.0681 - val_rmse: 0.1534 - learning_rate: 3.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - loss: 0.0105 - mae: 0.0637 - rmse: 0.1513 - val_loss: 0.0108 - val_mae: 0.0644 - val_rmse: 0.1534 - learning_rate: 3.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0633 - rmse: 0.1508 - val_loss: 0.0108 - val_mae: 0.0663 - val_rmse: 0.1530 - learning_rate: 3.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 0.0102 - mae: 0.0631 - rmse: 0.1488 - val_loss: 0.0108 - val_mae: 0.0647 - val_rmse: 0.1534 - learning_rate: 3.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - loss: 0.0101 - mae: 0.0625 - rmse: 0.1484 - val_loss: 0.0108 - val_mae: 0.0639 - val_rmse: 0.1535 - learning_rate: 3.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0623 - rmse: 0.1483 - val_loss: 0.0108 - val_mae: 0.0640 - val_rmse: 0.1536 - learning_rate: 3.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0622 - rmse: 0.1479 - val_loss: 0.0108 - val_mae: 0.0644 - val_rmse: 0.1537 - learning_rate: 3.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0618 - rmse: 0.1475 - val_loss: 0.0108 - val_mae: 0.0643 - val_rmse: 0.1536 - learning_rate: 3.0000e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0619 - rmse: 0.1477 - val_loss: 0.0108 - val_mae: 0.0643 - val_rmse: 0.1537 - learning_rate: 3.0000e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0618 - rmse: 0.1476 - val_loss: 0.0108 - val_mae: 0.0641 - val_rmse: 0.1537 - learning_rate: 3.0000e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m9121/9121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0618 - rmse: 0.1475 - val_loss: 0.0108 - val_mae: 0.0643 - val_rmse: 0.1537 - learning_rate: 3.0000e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "from src.models.nn_zero_inflated import build_dynamic_model_tuned\n",
    "\n",
    "model = build_dynamic_model_tuned(\n",
    "    embed_cols=embed_cols,\n",
    "    encoders=encoders,\n",
    "    n_numeric_features=n_nums,\n",
    "    learning_rate=3e-4,\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    callbacks.EarlyStopping(patience=8, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(patience=4),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    y_train,\n",
    "    validation_data=(test_inputs, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=cb,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Observacion:\n",
    "# “EarlyStopping\" y \"ReduceLROnPlateau\" reducen el riesgo de sobreentrenar y estabilizan el entrenamiento sin necesidad de grid-search manual de épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfbfd4",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b12579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2281/2281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "R2   : 0.7849\n",
      "MSE  : 0.023415\n",
      "RMSE : 0.153021\n",
      "MAE  : 0.066329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "preds = model.predict(test_inputs).reshape(-1)\n",
    "\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"R2   : {r2:.4f}\")\n",
    "print(f\"MSE  : {mse:.6f}\")\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_dir = MODELS_DIR / NN_MODEL_SUBDIR\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "keras_path = model_dir / NN_KERAS_NAME\n",
    "pipe_path = model_dir / NN_PIPELINE_PKL\n",
    "\n",
    "model.save(keras_path)\n",
    "\n",
    "pipeline_artefactos = {\n",
    "    \"keras_model_path\": keras_path,\n",
    "    \"encoders\": encoders,\n",
    "    \"scaler\": scaler,\n",
    "    \"embed_cols\": embed_cols,\n",
    "    \"num_cols\": num_cols,\n",
    "}\n",
    "\n",
    "joblib.dump(pipeline_artefactos, pipe_path)\n",
    "\n",
    "print(\"Modelo guardado en:\", keras_path)\n",
    "print(\"Pipeline guardado en:\", pipe_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c85e22",
   "metadata": {},
   "source": [
    "### Importancia por permutación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65fc741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_seccion_id: ΔRMSE = 0.267317\n",
      "in_numerics: ΔRMSE = 0.056576\n",
      "in_mp_id: ΔRMSE = 0.012455\n",
      "in_producto_id: ΔRMSE = 0.011733\n",
      "in_Tipo_TEJ: ΔRMSE = 0.000534\n",
      "in_maq_id: ΔRMSE = 0.000317\n",
      "in_estilo_id: ΔRMSE = 0.000010\n",
      "in_mp_categoria: ΔRMSE = 0.000002\n",
      "in_planta_id: ΔRMSE = 0.000000\n",
      "in_MP: ΔRMSE = -0.000008\n"
     ]
    }
   ],
   "source": [
    "from src.models.importance import calculate_permutation_importance\n",
    "\n",
    "# Métricas de Keras: [loss, mae, rmse] -> rmse está en índice 2\n",
    "RMSE_INDEX = 2\n",
    "\n",
    "imps = calculate_permutation_importance(\n",
    "    model=model,\n",
    "    X_dict=test_inputs,\n",
    "    y_true=y_test,\n",
    "    metric_index=RMSE_INDEX,\n",
    "    sample_size=10000,\n",
    ")\n",
    "\n",
    "sorted_imps = sorted(imps.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for name, imp in sorted_imps[:10]:\n",
    "    print(f\"{name}: ΔRMSE = {imp:.6f}\")\n",
    "    \n",
    "\n",
    "# Observacion:\n",
    "# Permutation importance a nivel de input dict permite validar si la arquitectura está usando las señales correctas y justificar exclusiones futuras. \n",
    "# No es una explicación local estilo SHAP, pero es suficientemente estable para decisiones de feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0f2c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
